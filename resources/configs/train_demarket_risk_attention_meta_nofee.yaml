risk-ppo:
    env: DecentralizedMarket
    run: PPO-RISK
    name: DEMRK PPO ATT RAA META NOFEE

    samples: 2

    stop:
        training_iteration: 8000
        # training_iteration: 3

    config:
        model:
            use_attention: true
            custom_action_dist: Dirichlet
            custom_model_config:
                risk_factor: 0.01
                risk_lr: 0.00003
                risk_net_layers: [32, 16]

        env_config:
            starting_funds: 100.0
            fee_model: no_fee
            meta_actions: true

        gamma: 0.99
        lr: 0.0004
        lambda: 0.8
        kl_coeff: 0.2
        vf_loss_coeff: 1.0
        entropy_coeff: 0.015
        clip_param: 0.2
        vf_clip_param: 9

        use_gae: true
        use_critic: true
        batch_mode: complete_episodes
        num_gpus: 0.49
        num_workers: 3
        framework: torch
        log_level: ERROR

        normalize_actions: false
